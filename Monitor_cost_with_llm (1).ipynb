{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a67cee54-83c3-4dba-8db6-16875bcfe491",
   "metadata": {},
   "source": [
    "Target of this notebook is to use langchain e GCP llm to monitor the cost of BQ jobs. The idea is to use the information schema table to ask the LLM to give me a daily list of the most expensive jobs. Second point is to use the LLM to optmise the SQL code if possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe82f91-5489-414b-8f75-b825efde98cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "first we install the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df30d9e4-91b1-490e-8459-297e3d79b435",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /home/jupyter/.local/lib/python3.10/site-packages (1.51.0)\n",
      "Requirement already satisfied: google-cloud-bigquery in /opt/conda/lib/python3.10/site-packages (3.21.0)\n",
      "Collecting google-cloud-bigquery\n",
      "  Downloading google_cloud_bigquery-3.22.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: langchain in /home/jupyter/.local/lib/python3.10/site-packages (0.1.19)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.34.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.29.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.23.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.20.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /home/jupyter/.local/lib/python3.10/site-packages (from google-cloud-aiplatform) (23.2)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.14.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.12.3)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.0.4)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.7.1)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (0.16)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery) (2.7.0)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery) (2.9.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery) (2.31.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/jupyter/.local/lib/python3.10/site-packages (from langchain) (0.6.5)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.38 in /home/jupyter/.local/lib/python3.10/site-packages (from langchain) (0.0.38)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /home/jupyter/.local/lib/python3.10/site-packages (from langchain) (0.1.52)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /home/jupyter/.local/lib/python3.10/site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/jupyter/.local/lib/python3.10/site-packages (from langchain) (0.1.56)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/jupyter/.local/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/jupyter/.local/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.63.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.62.2)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/jupyter/.local/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (4.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain) (2.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/jupyter/.local/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Downloading google_cloud_bigquery-3.22.0-py2.py3-none-any.whl (236 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.7/236.7 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: google-cloud-bigquery\n",
      "Successfully installed google-cloud-bigquery-3.22.0\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-aiplatform google-cloud-bigquery langchain --upgrade --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82218aac-000d-4af4-a396-a42092c1fc2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain version: 0.1.19\n",
      "Vertex AI SDK version: 1.51.0\n"
     ]
    }
   ],
   "source": [
    "import google.cloud.bigquery as bq\n",
    "import langchain\n",
    "from google.cloud import aiplatform\n",
    "from langchain.llms import VertexAI\n",
    "from langchain.document_loaders import BigQueryLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import format_document\n",
    "\n",
    "# Print LangChain and Vertex AI versions\n",
    "print(f\"LangChain version: {langchain.__version__}\")\n",
    "print(f\"Vertex AI SDK version: {aiplatform.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e45da91-5e95-4072-b8cc-466b6150fd76",
   "metadata": {},
   "source": [
    "we extract the infomation about the jobs from the INFORMATION_SCHEMA.JOBS table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d97aa21-3097-4315-934f-a761b564b753",
   "metadata": {},
   "source": [
    "First we define our foundation model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a5a4fed-2ef6-4072-8c4c-1a14ab675bf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `VertexAI` was deprecated in LangChain 0.0.12 and will be removed in 0.3.0. An updated version of the class exists in the langchain-google-vertexai package and should be used instead. To use it run `pip install -U langchain-google-vertexai` and import as `from langchain_google_vertexai import VertexAI`.\n",
      "  warn_deprecated(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'## INFORMATION SCHEMAS in SQL\\n\\nThe INFORMATION SCHEMAS are a standardized way to access metadata about your database. They are available in most SQL databases, including MySQL, PostgreSQL, and SQL Server. \\n\\n### What information do they contain?\\n\\nINFORMATION SCHEMAS contain a wealth of information about your database, including:\\n\\n* **Tables and views:** You can find information about the columns, data types, and constraints of each table and view.\\n* **Stored procedures and functions:** You can see the definition and parameters of stored procedures and functions.\\n* **Triggers:** You can learn about the events that trigger each trigger and the actions'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = VertexAI(model_name=\"gemini-pro\", temperature=0)\n",
    "\n",
    "llm(\"What are the INFORMATION SCHEMAS and how should I use them?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f1b80d-3853-49d8-bf88-59617baf09f5",
   "metadata": {},
   "source": [
    "Now let's define our query and laod the dataset with BQ loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29f4dafa-236f-4272-8f76-c08946043b44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `BigQueryLoader` was deprecated in LangChain 0.0.32 and will be removed in 0.3.0. An updated version of the class exists in the langchain-google-community package and should be used instead. To use it run `pip install -U langchain-google-community` and import as `from langchain_google_community import BigQueryLoader`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Define our query\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "  creation_time,\n",
    "  user_email,\n",
    "  job_id,\n",
    "  query,\n",
    "  total_bytes_billed,\n",
    "  6*total_bytes_billed/1e12 as total_cost_eur\n",
    "FROM\n",
    "  `jit-training-dma-devops.region-EU.INFORMATION_SCHEMA.JOBS`\n",
    "--WHERE user_email not like '%7728271103%'\n",
    "order by creation_time;\n",
    "\"\"\"\n",
    "\n",
    "# Load the data\n",
    "loader = BigQueryLoader(\n",
    "    query,metadata_columns=['creation_time','user_email'],page_content_columns=['creation_time','user_email','job_id','query','total_bytes_billed','total_cost_eur']\n",
    ")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a3c2d2a-b531-47fe-b6e8-609271c072fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='creation_time: 2024-04-08 23:27:34.719000+00:00\\nuser_email: alessandro.provenza@jakala.com\\njob_id: bquxjob_47d33dda_18ec009d77b\\nquery: \\r\\n  CREATE VIEW dev_ale.first_view AS\\r\\n  SELECT * FROM `jit-training-dma-devops.test_listing_ale_sub.test_pubsub`\\ntotal_bytes_billed: 0\\ntotal_cost_eur: 0.0', metadata={'creation_time': datetime.datetime(2024, 4, 8, 23, 27, 34, 719000, tzinfo=datetime.timezone.utc), 'user_email': 'alessandro.provenza@jakala.com'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fb787a-30f0-4b89-ab62-1ef504ddaf88",
   "metadata": {
    "tags": []
   },
   "source": [
    "Write the chain:\n",
    "- step 1 : define the LLM we want to use for the model, gemini-pro in this case\n",
    "- step 2 : define the chain that get as input the result of the query contained in the content fields\n",
    "- step 3 : pass the content to the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30b7f4e8-a322-4b19-b9ac-a916060f7150",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Top 20 Jobs by Bytes Billed in the Last Day\n",
      "\n",
      "Here's a list of the 20 jobs that used the most bytes in the last day, along with their cost and potential optimization suggestions:\n",
      "\n",
      "| Job ID | User Email | Query | Bytes Billed | Cost (EUR) | Optimization Suggestion |\n",
      "|---|---|---|---|---|---|\n",
      "| bquxjob_4f8673ff_18f3495e68d | riccardo.rubini@jakala.com | `SELECT * FROM `jit-training-dma-devops.region-EU.INFORMATION_SCHEMA.JOBS` | 1060110336 | 0.006360662016 | Consider filtering the data to reduce the amount scanned. |\n",
      "| bquxjob_79a43895_18f349eb711 | riccardo.rubini@jakala.com | `SELECT user_email, job_id, query, total_bytes_billed FROM `jit-training-dma-devops.region-EU.INFORMATION_SCHEMA.JOBS` | 281018368 | 0.001686110208 | Consider using a smaller subset of columns or filtering the data. |\n",
      "| bquxjob_8cc49b4_18f349eeac7 | riccardo.rubini@jakala.com | `SELECT *, user_email, job_id, query, total_bytes_billed FROM `jit-training-dma-devops.region-EU.INFORMATION_SCHEMA.JOBS` | 1060110336 | 0.006360662016 | Consider filtering the data to reduce the amount scanned. |\n",
      "| bquxjob_38a9648a_18f349f719f | riccardo.rubini@jakala.com | `SELECT creation_time, user_email, job_id, query, total_bytes_billed FROM `jit-training-dma-devops.region-EU.INFORMATION_SCHEMA.JOBS` order by creation_time;` | 281018368 | 0.001686110208 | Consider using a smaller subset of columns or filtering the data. |\n",
      "| bquxjob_1acfb97b_18f2b829acb | riccardo.rubini@jakala.com | `CREATE FUNCTION `jit-training-dma-devops`.remote_functions_dataset.remote_hash(x STRING) RETURNS STRING REMOTE WITH CONNECTION `jit-training-dma-devops.eu.remote-function-connection` OPTIONS (endpoint = ' https://us-central1-jit-training-dma-devops.cloudfunctions.net/remote_hash')` | None | None | N/A |\n",
      "| bquxjob_2116dc4e_18f2b87c9ad | riccardo.rubini@jakala.com | `INSERT `jit-training-dma-devops.remote_functions_dataset_v2.remote_functions_table_native` (id, name) VALUES(10, 'John'), (400, 'Mike'), (333, 'Luke')` | 0 | 0.0 | N/A |\n",
      "| bquxjob_20f347ed_18f2b891c71 | riccardo.rubini@jakala.com | `CREATE FUNCTION `jit-training-dma-devops`.remote_functions_dataset_v2.remote_hash(x STRING) RETURNS STRING REMOTE WITH CONNECTION `jit-training-dma-devops.EU.remote-function-connection` OPTIONS (endpoint = 'https://europe-west3-jit-training-dma-devops.cloudfunctions.net/remote_hash')` | 0 | 0.0 | N/A |\n",
      "| bquxjob_2f462c42_18f2b89d1bd | riccardo.rubini@jakala.com | `SELECT `jit-training-dma-devops.remote_functions_dataset_v2.remote_hash`('abc');` | 0 | 0.0 | N/A |\n",
      "| bquxjob_2aa62064_18f2b8c162a | riccardo.rubini@jakala.com | `SELECT * FROM `jit-training-dma-devops.remote_functions_dataset_v2.remote_functions_table_native` LIMIT 1000` | 10485760 | 6.291456e-05 | Consider using a smaller subset of columns or filtering the data. |\n",
      "| bquxjob_54cfe396_18f2b8c7192 | riccardo.rubini@jakala.com | `SELECT id, `jit-training-dma-devops.remote_functions_dataset_v2.remote_hash`(name) as name FROM `jit-training-dma-devops.remote_functions_dataset_v2.remote_functions_table_native` ` | 10485760 | 6.291456e-05 | Consider using a smaller subset of columns or filtering the data. |\n",
      "| bquxjob_4e527667_18f2de3f71c | riccardo.rubini@jakala.com | `SELECT `jit-training-dma-devops.remote_functions_dataset_v2.remote_hash`(name) as name FROM `jit-training-dma-devops.remote_functions_dataset_v2.remote_functions_table_native` ` | 10485760 | 6.291456e-05 | Consider using a smaller subset of columns or filtering the data. |\n",
      "| bquxjob_38ebae75_18f2de7c91c | riccardo.rubini@jakala.com | `SELECT `jit-training-dma-devops.remote_functions_dataset_v2.remote_hash`(name) as name FROM `jit-training-dma-devops.remote_functions_dataset_v2.remote_functions_table_native` ` | 10485760 | 6.291456e-05 | Consider using a smaller subset of columns or filtering the data. |\n",
      "| bquxjob_6253ce8f_18f2df28e2f | riccardo.rubini@jakala.com | `SELECT `jit-training-dma-devops.remote_functions_dataset_v2.remote_hash`(name) as name FROM `jit-training-dma-devops.remote_functions_dataset_v2.remote_functions_table_native` ` | 10485760 | 6.291456e-05 | Consider using a smaller subset of columns or filtering the data. |\n",
      "| bquxjob_758cea0_18ec00a67ec | alessandro.provenza@jakala.com | `CREATE TABLE dev_ale.first_table AS SELECT * FROM `jit-training-dma-devops.test_listing_ale_sub.test_pubsub`;` | 10485760 | 6.291456e-05 | Consider using a smaller subset of columns or filtering the data. |\n",
      "| bquxjob_3ff39923_18ec01e0bd8 | alessandro.provenza.gcp@jakala.com | `SELECT distinct * FROM `jit-training-dma-devops.test_listing_ale_sub.test_pubsub` LIMIT 1000` | 10485760 | 6.291456e-05 | Consider using a smaller subset of columns or filtering the data. |\n",
      "| bquxjob_47d33dda_18ec009d77b | alessandro.provenza@jakala.com | `CREATE VIEW dev_ale.first_view AS SELECT * FROM `jit-training-dma-devops.test_listing_ale_sub.test_pubsub` ` | 0 | 0.0 | N/A |\n",
      "\n",
      "**Note:**\n",
      "\n",
      "* The optimization suggestions are based on the assumption that the goal is to reduce the amount of data scanned and processed.\n",
      "* The actual optimization strategy may vary depending on the specific use case and requirements.\n",
      "* Some jobs may not have optimization suggestions because they are already optimized or because the query is not available.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use code generation model\n",
    "llm = VertexAI(model_name=\"gemini-pro\", max_output_tokens=4096)\n",
    "\n",
    "# Define the chain\n",
    "chain = (\n",
    "    {\n",
    "        \"content\": lambda docs: \"\\n\\n\".join(\n",
    "            format_document(doc, PromptTemplate.from_template(\"{page_content}\"))\n",
    "            for doc in docs\n",
    "        )\n",
    "    }\n",
    "    | PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Give me a list of the 20 jobs that used more bytes in the last day,report the cost as well. \n",
    "        Examine the query that is used for each job and propose an optimisation :\\n\\n{content}\n",
    "        \"\"\"\n",
    "    )\n",
    "    # | PromptTemplate.from_template(\n",
    "    #     \"Give me the amout of bytes and the total cost for each user :\\n\\n{content}\"\n",
    "    # )\n",
    "    | llm\n",
    ")\n",
    "\n",
    "# Invoke the chain with the documents, and remove code backticks\n",
    "result = chain.invoke(data).strip(\"```\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a9b0f6-60b4-447c-b95a-af0af3137036",
   "metadata": {
    "tags": []
   },
   "source": [
    "TODO: use function calling to return this data into a format suitable to be loaded into a pandas dataframe. \n",
    "\n",
    "Test implementation of the same chain with the addition of the function calling to obtain a structured output\n",
    "\n",
    "The actual structured outputt is the following: | Job ID | User Email | Query | Total Bytes Billed | Total Cost (EUR) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "838225bb-8778-48e4-9760-58b356defcc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import the needed libraries to implement the function calling\n",
    "from vertexai.generative_models import (\n",
    "    FunctionDeclaration,\n",
    "    GenerativeModel,\n",
    "    GenerationConfig,\n",
    "    GenerationResponse,\n",
    "    Tool,\n",
    ")\n",
    "\n",
    "from vertexai.preview.generative_models import ToolConfig\n",
    "\n",
    "from proto.marshal.collections import repeated\n",
    "from proto.marshal.collections import maps\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de1139f4-2b16-4b2f-8da5-857ea8d25cd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Helper functions\n",
    "\n",
    "\n",
    "def recurse_proto_repeated_composite(repeated_object):\n",
    "    repeated_list = []\n",
    "    for item in repeated_object:\n",
    "        if isinstance(item, repeated.RepeatedComposite):\n",
    "            item = recurse_proto_repeated_composite(item)\n",
    "            repeated_list.append(item)\n",
    "        elif isinstance(item, maps.MapComposite):\n",
    "            item = recurse_proto_marshal_to_dict(item)\n",
    "            repeated_list.append(item)\n",
    "        else:\n",
    "            repeated_list.append(item)\n",
    "\n",
    "    return repeated_list\n",
    "\n",
    "\n",
    "def recurse_proto_marshal_to_dict(marshal_object):\n",
    "    new_dict = {}\n",
    "    for k, v in marshal_object.items():\n",
    "        if not v:\n",
    "            continue\n",
    "        elif isinstance(v, maps.MapComposite):\n",
    "            v = recurse_proto_marshal_to_dict(v)\n",
    "        elif isinstance(v, repeated.RepeatedComposite):\n",
    "            v = recurse_proto_repeated_composite(v)\n",
    "        new_dict[k] = v\n",
    "\n",
    "    return new_dict\n",
    "\n",
    "\n",
    "def get_text(response: GenerationResponse):\n",
    "    \"\"\"Returns the Text from the Generation Response object.\"\"\"\n",
    "    part = response.candidates[0].content.parts[0]\n",
    "    try:\n",
    "        text = part.text\n",
    "    except:\n",
    "        text = None\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_function_name(response: GenerationResponse):\n",
    "    return response.candidates[0].content.parts[0].function_call.name\n",
    "\n",
    "\n",
    "def get_function_args(response: GenerationResponse) -> dict:\n",
    "    return recurse_proto_marshal_to_dict(\n",
    "        response.candidates[0].content.parts[0].function_call.args\n",
    "    )\n",
    "\n",
    "\n",
    "def pprint(params):\n",
    "    print(json.dumps(params, sort_keys=True, indent=2, separators=(\",\", \": \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c29c9d92-9634-4a1b-83ab-96baa119f652",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_structured_output = FunctionDeclaration(\n",
    "    name=\"get_structured_output\",\n",
    "    description=\"format the input string in a structured way. The fields are divided by | while each row rapresents a different record\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"job_id\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"job id of the considered bigquery job it is the first field\",\n",
    "            },\n",
    "            \"user_email\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"mail of the user that run for each job it is the seccond field for each row\",\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"the sql query of each job used to \",\n",
    "            },\n",
    "            \"total_bytes_billed\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"total amount of billed bytes associated to each job\",\n",
    "            },\n",
    "             \"opimised_query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"proposition of opmisation for the sql query associated to a certain job\",\n",
    "            },\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "formatting_tool = Tool(\n",
    "    function_declarations=[get_structured_output]\n",
    ")\n",
    "tool_config = ToolConfig(\n",
    "    function_calling_config=ToolConfig.FunctionCallingConfig(\n",
    "        mode=ToolConfig.FunctionCallingConfig.Mode.AUTO,  # The default model behavior. The model decides whether to predict a function call or a natural language response.\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a7d0c6f-46f2-4b15-94d9-5ede895fcd4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GenerativeModel(\n",
    "    \"gemini-1.0-pro-001\", generation_config=GenerationConfig(temperature=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f5f455d-4396-43f7-9373-85fa7118d213",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"query\": \"SELECT \\n  creation_time,\\n  user_email,\\n  job_id,\\n  query,\\n  total_bytes_billed\\nFROM\\n  `jit-training-dma-devops.region-EU.INFORMATION_SCHEMA.JOBS`\\norder by creation_time;\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Use the precedent output to ouput the model into the structure defined into the function calling\n",
    "\n",
    "\n",
    "prompt =f\"\"\"Extract job_id,user_email,query,total bytes billed and cost from the following string. \n",
    "        Split the lines with \\n\\n\n",
    "        \\n\\n {result}\n",
    "        \"\"\"\n",
    "\n",
    "response = model.generate_content(\n",
    "    prompt,\n",
    "    tools=[formatting_tool],\n",
    "    tool_config=tool_config\n",
    ")\n",
    "\n",
    "params = get_function_args(response)\n",
    "pprint(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42a9d2f8-681d-4394-9447-de121e49daf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT \n",
      "  creation_time,\n",
      "  user_email,\n",
      "  job_id,\n",
      "  query,\n",
      "  total_bytes_billed\n",
      "FROM\n",
      "  `jit-training-dma-devops.region-EU.INFORMATION_SCHEMA.JOBS`\n",
      "order by creation_time;\n"
     ]
    }
   ],
   "source": [
    "print(params['query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0300a775-0393-4578-8709-a662ec9f244c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
